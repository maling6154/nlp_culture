{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/r1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/r1/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/r1/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/r1/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word, TextBlob\n",
    "from collections import Counter\n",
    "import six\n",
    "import textblob\n",
    "import gensim\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemma_textblob(raw_text):\n",
    "    \"\"\"\n",
    "    Get lemma from text\n",
    "    :param raw_text: Raw text to get lemma from\n",
    "    :type raw_text: str\n",
    "    :rtype: list of lemmas\n",
    "    \"\"\"\n",
    "    blob = TextBlob(raw_text)\n",
    "    return [Word(tag[0], tag[1]).lemma.lower() for tag in blob.pos_tags]\n",
    "\n",
    "def filter_corpus(text_corpus, words_to_keep = [], words_to_filter = [], n_most_common=0, \n",
    "                  rare_words_threshold=10, replace_rare = False):\n",
    "    \"\"\"\n",
    "    Filter out most common, rare, and user supplied words\n",
    "    :param corpus: a list of list of lemmas as a corpus\n",
    "    :param words_to_filter: a set of words to filter\n",
    "    :param n_most_common: top n most frequent words to remove\n",
    "    :param rare_words_threshold: filter out words if frequency is less than the threshold\n",
    "    :param replace_rare: if true replace rare words using \"UNK\", else remove rare words\n",
    "    :return: a list of list of lemmas as a corpus\n",
    "    \"\"\"\n",
    "    print(\"Start filtering\")\n",
    "    # remove any token that contains only digit and punctuations\n",
    "    text_corpus = [[word for word in sub_list if any(c.isalpha() for c in word)] for sub_list in text_corpus]\n",
    "    all_tokens = [item for sub_list in text_corpus for item in sub_list]  # flatten the corpus list\n",
    "    \n",
    "    c = Counter(all_tokens)\n",
    "    common_words = [pair[0] for pair in c.most_common(n_most_common) if pair[0] not in words_to_keep] + [\"\"]\n",
    "    #print(\"The most %d common words:\"%(n_most_common))\n",
    "    #print(common_words)\n",
    "    #print(\"Filtered stop words:\")\n",
    "    #print(words_to_filter)\n",
    "    if replace_rare is True:\n",
    "        filtered = set(common_words + list(words_to_filter))\n",
    "        rare_words = set([k for k, v in six.iteritems(c) if v <= rare_words_threshold and k not in words_to_keep])\n",
    "        text_corpus = [['UNK' if word in rare_words else word for word in text] for text in text_corpus]\n",
    "    else:\n",
    "        rare_words = [k for k, v in six.iteritems(c) if v <= rare_words_threshold and k not in words_to_keep]\n",
    "        filtered = set(common_words + rare_words + list(words_to_filter))\n",
    "    #print(\"Rare words:\")\n",
    "    #print(rare_words)\n",
    "    texts = [[str(word) for word in text if word not in filtered] for text in text_corpus]\n",
    "    print(\"Done filtering\")\n",
    "    return texts\n",
    "\n",
    "def text_processing(additional_stop_words = [], words_to_keep = [], n_most_common=100, \n",
    "                    rare_words_threshold = 5, replace_rare=False, gram='bigram', bigram=10):\n",
    "    \"\"\"\n",
    "    - load data\n",
    "    - lemmatization\n",
    "    - remove common words and rare words\n",
    "    - get n_gram tokens\n",
    "    :param additional_stop_words: tailor-made words to remove for the corpus\n",
    "    :type additional_stoop_words: list of str\n",
    "    :param n_most_common,rare_words_threshold,replace_rare: same with function filter_corpus()\n",
    "    :param gram: 'unigram', 'bigram', 'trigram', phrases length using gensim\n",
    "    :type gram: str\n",
    "    :param bigram: threshold for genism phrase\n",
    "    :type bigram: int\n",
    "    :return: clean tokenized documents\n",
    "    :rtype: list of list\n",
    "    \"\"\"\n",
    "#     print('Loading raw text data')\n",
    "#     sec_10k = pd.read_pickle('data/10k_raw.pickle')\n",
    "#     #raw = sec_10k.head().copy()\n",
    "#     #raw_documents = raw['mda_text'].tolist()\n",
    "#     raw_documents = sec_10k['mda_text'].tolist()\n",
    "#     #raw_documents = raw_documents[0:10]\n",
    "#     print('Lemmatizating')\n",
    "#     lemma_documents = [get_lemma_textblob(document) for document in raw_documents]\n",
    "#     pickle.dump(lemma_documents, file=open(\"data/lemma_documents.pickle\", 'wb'))\n",
    "    print('Loading lemmatized documents')\n",
    "    lemma_documents = pickle.load(file=open(\"data/10k_lemmatized.pickle\", 'rb'))\n",
    "    \n",
    "    print('Cleaninng')\n",
    "    stop_words = stopwords.words('english') + additional_stop_words\n",
    "    clean_documents = filter_corpus(lemma_documents, words_to_keep, stop_words, n_most_common, rare_words_threshold, \n",
    "                                   replace_rare)\n",
    "    \n",
    "    print('N_gram')\n",
    "    if gram == 'unigram':\n",
    "        return clean_documents\n",
    "    if gram == 'bigram':\n",
    "        bigram_transformer = gensim.models.Phrases(clean_documents, min_count=10, threshold=bigram)\n",
    "        bigram = list(bigram_transformer[clean_documents])\n",
    "        return bigram\n",
    "    if gram == 'trigram':\n",
    "        bigram_transformer = gensim.models.Phrases(clean_documents, min_count=1)\n",
    "        bigram = list(bigram_transformer[clean_documents])\n",
    "        trigram_transformer = gensim.models.Phrases(bigram, min_count=1)\n",
    "        trigram = list(trigram_transformer[bigram])\n",
    "        return trigram\n",
    "\n",
    "\n",
    "def similar_words(word2vec_model, dimension, n=5):\n",
    "    \"\"\"\n",
    "    Note: not used\n",
    "    given a dimension of seed word or list of seed words find most similar words in word2vec corpus, based on cosine similarity\n",
    "    :param word2vec_model: gensim word2vec model\n",
    "    :type dimension: str\n",
    "    :param n: the most n similar words\n",
    "    :type n: int\n",
    "    :rtype: list of (similar_word, similarity) tuples\n",
    "    \"\"\"\n",
    "    similar_words = []\n",
    "    for word in seed_words[dimension]:\n",
    "        if isinstance(word, list):\n",
    "            #make sure every word in seed word list is in word2vec corpus\n",
    "            updated_word = [item for item in word if item in word2vec_model.vocab]\n",
    "            try:\n",
    "                for pair in word2vec_model.most_similar(updated_word, topn=n):\n",
    "                    similar_words.append(pair)\n",
    "            except:\n",
    "                pass\n",
    "                #similar_words[', '.join(word)] = ('All the words in this seed word list not found in corpus', 0)\n",
    "        else:\n",
    "            try:\n",
    "                for pair in word2vec_model.similar_by_word(word, topn=n):\n",
    "                    similar_words.append(pair)\n",
    "            except:\n",
    "                pass\n",
    "                #similar_words[word] = ('Seed word not found in corpus', 0)\n",
    "    return similar_words\n",
    "\n",
    "\n",
    "def train_word2vec_model(documents, fname, min_count=5, size=100, window=5, workers=16):\n",
    "    print('Building word2vec model')\n",
    "    model = gensim.models.Word2Vec(documents, min_count=min_count, size=size, window=window, workers=workers)\n",
    "    model.save(fname)\n",
    "    model.init_sims(replace=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def expand_words(word2vec_model, n=50, restrict=None):\n",
    "    vocab_number = len(word2vec_model.vocab)\n",
    "    expanded_words = {}\n",
    "    if restrict != None:\n",
    "        restrict = int(vocab_number*restrict)\n",
    "    for dimension in seed_words:\n",
    "        dimension_words = [word for word in seed_words[dimension] if word in word2vec_model.vocab]\n",
    "        similar_words = [pair[0] for pair in word2vec_model.most_similar(dimension_words, topn=n, restrict_vocab=restrict)]\n",
    "        expanded_words[dimension] = similar_words\n",
    "    return expanded_words\n",
    "                \n",
    "\n",
    "def output_result(expanded_words, seed_words, n, fname):\n",
    "    result = {}\n",
    "    for dimension in seed_words:\n",
    "        result[dimension] = []\n",
    "    for k, v in expanded_words.items():\n",
    "        for expanded_word_tuple in v:\n",
    "            result[k].append(expanded_word_tuple)\n",
    "        result[k].sort(key=lambda tup: tup[1], reverse=True)\n",
    "    with open(fname, 'w') as text_file:\n",
    "        for k in result:\n",
    "            result[k] = [tup[0] for tup in result[k]]\n",
    "            if len(result[k]) >= n:\n",
    "                result[k] = result[k][0:n]\n",
    "                print(\"The dimension is: {} {} words\".format(k, n), file=text_file)\n",
    "                print(\"===========================================================================\", file=text_file)\n",
    "                print(result[k], file=text_file)\n",
    "                print('\\n', file=text_file)\n",
    "            else:\n",
    "                print(\"The dimension is: {}. Less than {}words, output {}.\".format(k, n, len(result[k])), file=text_file)\n",
    "                print(\"===========================================================================\", file=text_file)\n",
    "                print(result[k], file=text_file)\n",
    "                print('\\n', file=text_file)\n",
    "    return result\n",
    "\n",
    "def output_dimension_result(expanded_words, n, fname):\n",
    "    with open(fname, 'w') as text_file:\n",
    "        for k, v in expanded_words.items():\n",
    "            print(\"The dimension is: {} {} expanded words\".format(k, n), file=text_file)\n",
    "            print(\"===========================================================================\", file=text_file)\n",
    "            print(v, file=text_file)\n",
    "            print('\\n', file=text_file)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct original seed words based on six culture dimensions, for every dimension, only choose words with positive loadings greater than 0.4 and update using self judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_words_oreilly = {\"adaptability\":\n",
    "[\"being_innovative\", \"be_innovative\", \"risk_taking\", \"risk_taken\",\"take_risk\", \"being_willing_to_experiment\", \"fast_moving\",\n",
    "\"being_quick_to_take_advantage_of_opportunities\", \"not_being_constrained_by_many_rules\", \"adaptability\"],\n",
    "\"integrity\":\n",
    "[\"having_integrity\", 'have_integrity', 'be_honest', \"having_high_ethical_standards\", \"being_honest\", \"respecting_individuals\",\n",
    "\"being_fair\", 'be_fair', 'be_supportive'],\n",
    "\"collaborative\":[\"working_in_collaboration_with_others\", \"being_team_oriented\", \"cooperative\", \"being_supportive\",\n",
    "\"avoiding_conflict\", 'be_supportive', 'avoid_conflict'],\n",
    "\"results_oriented\":['results_oriented', \"being_results_oriented\", \"having_high_expectations_for_performance\", \"achievement_oriented\"],\n",
    "\"customer_oriented\":['customer_oriented', \"being_customer_oriented\", \"listening_to_customers\", \"being_market_driven\", 'market_driven'],\n",
    "\"detail_oriented\":[\"paying_attention_to_detail\", \"emphasizing_quality\", 'emphasize_quality', \"being_precise\", 'be_precise', 'detail', 'precise', \n",
    "                  'detail_oriented']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_words = {\"integrity\":[\"integrity\", \"ethics\", \"accountability\", \"trust\", \"honesty\", \n",
    "                           \"responsibility\", \"fairness\", \"transparency\", \n",
    "                           \"ownership\", \"fair\", \"honest\", \n",
    "                           \"ethical\", \"transparent\"],\n",
    "\"teamwork\":[\"teamwork\", \"collaboration\", \"cooperation\", \"collaborative\", \"cooperative\"],\n",
    "\"innovation\":[\"innovation\", \"creativity\", \"excellence\", \"improvement\", \"passion\", \n",
    "              \"pride\", \"leadership\", \"growth\", \"performance\", \"efficiency\", \n",
    "              \"efficient\", \"results\", \"result\", 'innovative', 'creative'],\n",
    "\"respect\":[\"respect\", \"diversity\", \"inclusion\", \"development\", \n",
    "           \"talent\", \"employees\", \"employee\", \n",
    "           \"dignity\", \"empowerment\"],\n",
    "\"quality\":[\"quality\", \"customer\", \"meet_needs\", 'meet_need', \n",
    "           \"commitment\", \"make_a_difference\", \"dedication\", \n",
    "           \"value\", \"exceed_expectations\", 'exceed_expectation'],\n",
    "\"safety\":[\"safety\", \"health\", \"healthy\", \"work_life_balance\", \"flexibility\"],\n",
    "\"community\":[\"community\", \"environment\", \"caring\", \"citizenship\"],\n",
    "\"communication\":[\"communication\", \"openness\"],\n",
    "\"hard_work\":[\"hard_work\", \"reward\", \"fun\", \"energy\"]}\n",
    "\n",
    "bigram = {\"bigrams\":['being_innovative', 'be_innovative', 'risk_taking', 'risk_taken', 'take_risk', 'fast_moving', 'move_fast', \n",
    "          'have_integrity', 'having_integrity', 'be_honest', 'being_honest', 'respecting_individuals', 'respecting_individual', \n",
    "          'respect_individuals', 'respect_individual', 'being_fair', 'be_fair', 'be_supportive', 'avoiding_conflict', \n",
    "          'avoid_conflict', 'results_oriented', 'result_oriented', 'achievement_oriented', 'customer_oriented', \n",
    "          'market_driven', 'detail_oriented', 'emphasizing_quality', 'emphasize_quality', 'being_precise', \n",
    "          'be_precise']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_keep = []\n",
    "for dimension, word_list in seed_words.items():\n",
    "    for word in word_list:\n",
    "        if isinstance(word, str):\n",
    "            words_to_keep.append(word)\n",
    "words_to_remove = ['rx', 'chmp', 'spse', '-results', 'cia', 'openness', 'and/or', 'apb', 'cpt', 'qt', 'cte', 'mkg', 'nhs', \n",
    "                  '1350', 'rep', 'iplex', 'hap-tm-', 'hap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before adding words_to_keep result\n",
    "# documents = text_processing()\n",
    "# expanded_words = expand_seed_words(documents=documents)\n",
    "# for k, v in expanded_words.items():\n",
    "#     print('Culture dimension: %s' %(k))\n",
    "#     print('=========================================================================================================')\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # after adding words_to_keep unigram result\n",
    "# documents = text_processing(additional_stop_words=words_to_remove, words_to_keep=words_to_keep)\n",
    "# expanded_words_unigram = expand_seed_words(documents=documents, fname='data/10k_unigram')\n",
    "\n",
    "# pickle.dump(expanded_words_unigram, file=open(\"data/10k_expanded_unigram.pickle\", 'wb'))\n",
    "# del documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lemmatized documents\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# after adding words_to_keep bigram result phrase threshold=10\n",
    "documents = text_processing(additional_stop_words=words_to_remove, words_to_keep=words_to_keep, n_most_common=100, \n",
    "                            rare_words_threshold=5, replace_rare=False, gram='bigram', bigram=20)\n",
    "model = train_word2vec_model(documents=documents, fname='model/10k_bigram_10')\n",
    "\n",
    "expanded_words_100 = expand_words(word2vec_model=model, n=50, restrict=None)\n",
    "expanded_words_80 = expand_words(word2vec_model=model, n=50, restrict=0.8)\n",
    "expanded_words_50 = expand_words(word2vec_model=model, n=50, restrict=0.5)\n",
    "expanded_words_10 = expand_words(word2vec_model=model, n=50, restrict=0.1)\n",
    "\n",
    "output_dimension_result(expanded_words_100, fname='data/outputs/10k_expanded_words_100.txt', n=50)\n",
    "output_dimension_result(expanded_words_80, fname='data/outputs/10k_expanded_words_80.txt', n=50)\n",
    "output_dimension_result(expanded_words_50, fname='data/outputs/10k_expanded_words_50.txt', n=50)\n",
    "output_dimension_result(expanded_words_10, fname='data/outputs/10k_expanded_words_10.txt', n=50)\n",
    "\n",
    "#del documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump results expanded words as a list\n",
    "with open(\"data/model/10k_w2v.pickle\", \"wb\") as file:\n",
    "    pickle.dump(expand_words(word2vec_model=model, n=50, restrict=0.5), file= file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'communication': ['telecommunication',\n",
       "  'connectivity',\n",
       "  'networking',\n",
       "  'wireless',\n",
       "  'network',\n",
       "  'mobile',\n",
       "  'telephone',\n",
       "  'internet',\n",
       "  'wireless_wireline',\n",
       "  'wired_wireless',\n",
       "  'video_conferencing',\n",
       "  'voice',\n",
       "  'broadband',\n",
       "  'piv',\n",
       "  'machine-to-machine',\n",
       "  'infrastructure',\n",
       "  'high-speed',\n",
       "  'electronic',\n",
       "  'datacenter',\n",
       "  'gps_tracking',\n",
       "  'terrestrial-based',\n",
       "  'hailing',\n",
       "  'voice_message',\n",
       "  'networked',\n",
       "  'messaging',\n",
       "  'message',\n",
       "  'telephony',\n",
       "  'digital',\n",
       "  'instant_messaging',\n",
       "  'encrypt',\n",
       "  'satellite-based_communication',\n",
       "  'intelligence',\n",
       "  'telemetry',\n",
       "  'wireline_wireless',\n",
       "  'automation',\n",
       "  'computing',\n",
       "  'wirelessly',\n",
       "  'server_router',\n",
       "  'notebook_webcam',\n",
       "  'router_switch',\n",
       "  'chat',\n",
       "  'solution',\n",
       "  'intranet',\n",
       "  'interface',\n",
       "  'communications',\n",
       "  'server',\n",
       "  'telecom',\n",
       "  'greeting',\n",
       "  'telepresence',\n",
       "  'in-building_wireless'],\n",
       " 'community': ['foster',\n",
       "  'well-being',\n",
       "  'environmental_stewardship',\n",
       "  'culture',\n",
       "  'nonprofit_organization',\n",
       "  'low-_moderate-income',\n",
       "  'non-profit_organization',\n",
       "  'community-based',\n",
       "  'foundation',\n",
       "  'healthy_living',\n",
       "  'advocate',\n",
       "  'professionalism',\n",
       "  'urban',\n",
       "  'elderly',\n",
       "  'homeownership',\n",
       "  'everyone',\n",
       "  'psychology',\n",
       "  'chronic_disease',\n",
       "  'orientation',\n",
       "  'organization',\n",
       "  'for-profit',\n",
       "  'ecological',\n",
       "  'landscape',\n",
       "  'empowerment',\n",
       "  'career',\n",
       "  'educator',\n",
       "  'health_well-being',\n",
       "  'science-based',\n",
       "  'safer',\n",
       "  'workplace',\n",
       "  'youth_sport',\n",
       "  'resilience',\n",
       "  'policymakers',\n",
       "  'neighborhood',\n",
       "  'population',\n",
       "  'marketplace',\n",
       "  'prison',\n",
       "  'outreach',\n",
       "  'vibrant',\n",
       "  'entrepreneur',\n",
       "  'globally',\n",
       "  'math_science',\n",
       "  'deep_root',\n",
       "  'sexual',\n",
       "  'school',\n",
       "  'non-profit',\n",
       "  'advocacy',\n",
       "  'mental',\n",
       "  'backdrop',\n",
       "  'best-in-class'],\n",
       " 'hard_work': ['loyalty',\n",
       "  'friendly',\n",
       "  'passion',\n",
       "  'fan',\n",
       "  'exciting',\n",
       "  'rewards',\n",
       "  'favorite',\n",
       "  'unrivaled',\n",
       "  'shopping',\n",
       "  'tasting',\n",
       "  'knot',\n",
       "  'exceptional',\n",
       "  'enjoyment',\n",
       "  'online',\n",
       "  'everyone',\n",
       "  'instant_booking',\n",
       "  'lifestyle',\n",
       "  'endless',\n",
       "  'personalized',\n",
       "  'promotes',\n",
       "  'excitement',\n",
       "  'tweens',\n",
       "  'dignity',\n",
       "  'powerful',\n",
       "  'breakfast',\n",
       "  'guest',\n",
       "  '1-800-flowers.com',\n",
       "  'prize',\n",
       "  'self-service',\n",
       "  'personalization',\n",
       "  'dream',\n",
       "  'choice',\n",
       "  'promote',\n",
       "  'iconic',\n",
       "  'cabela',\n",
       "  'multi-channel',\n",
       "  'monster',\n",
       "  'dining',\n",
       "  'journey',\n",
       "  'enthusiast',\n",
       "  'compelling',\n",
       "  'contemporary',\n",
       "  'traveler',\n",
       "  'nutritious',\n",
       "  'instant',\n",
       "  'tween_girl',\n",
       "  'passionate',\n",
       "  'award-winning',\n",
       "  'wow',\n",
       "  'smart'],\n",
       " 'innovation': ['world-class',\n",
       "  'industry-leading',\n",
       "  'best-in-class',\n",
       "  'operational_excellence',\n",
       "  'competency',\n",
       "  'teamwork',\n",
       "  'differentiated',\n",
       "  'powerful',\n",
       "  'talent',\n",
       "  'focus',\n",
       "  'distinctive',\n",
       "  'productivity',\n",
       "  'resilience',\n",
       "  'unparalleled',\n",
       "  'enhancing',\n",
       "  'ease-of-use',\n",
       "  'customer-focused',\n",
       "  'personalized',\n",
       "  'personalize',\n",
       "  'enrich',\n",
       "  'smarter',\n",
       "  'award-winning',\n",
       "  'capability',\n",
       "  'idea',\n",
       "  'adaptability',\n",
       "  'rewarding',\n",
       "  'fun',\n",
       "  'time-to-market',\n",
       "  'improve',\n",
       "  'eco-friendly',\n",
       "  'holistic',\n",
       "  'compelling',\n",
       "  'leader',\n",
       "  'enhance',\n",
       "  'positioning',\n",
       "  'transform',\n",
       "  'modern',\n",
       "  'passionate',\n",
       "  'exceptional',\n",
       "  'appearance',\n",
       "  'culture',\n",
       "  'orientation',\n",
       "  'scalability',\n",
       "  'embrace',\n",
       "  'reinforce',\n",
       "  'customer-centric',\n",
       "  'unrivaled',\n",
       "  'excellent',\n",
       "  'market-leading',\n",
       "  'exciting'],\n",
       " 'integrity': ['governance',\n",
       "  'instill',\n",
       "  'accountable',\n",
       "  'empower',\n",
       "  'ethic',\n",
       "  'identity',\n",
       "  'coordination',\n",
       "  'teamwork',\n",
       "  'culture',\n",
       "  'tone_top',\n",
       "  'compassion',\n",
       "  'actionable',\n",
       "  'safeguard',\n",
       "  'corporate_governance',\n",
       "  'environmental_stewardship',\n",
       "  'professionalism',\n",
       "  'dmms',\n",
       "  'framework',\n",
       "  'mindset',\n",
       "  'cybersecurity',\n",
       "  'holistic',\n",
       "  'uniformity',\n",
       "  'collaborative_entrepreneurial',\n",
       "  'cross-functional_team',\n",
       "  'decision-making',\n",
       "  'background_check',\n",
       "  'abusive',\n",
       "  'honesty_integrity',\n",
       "  'abusive_practice',\n",
       "  'strict',\n",
       "  'cohesive',\n",
       "  'best-in-class',\n",
       "  'oversight',\n",
       "  'erm_framework',\n",
       "  'promotes',\n",
       "  'uniform',\n",
       "  'supervise',\n",
       "  'foster_culture',\n",
       "  'pcx_equities',\n",
       "  'adherence',\n",
       "  'administers',\n",
       "  'analytics-driven',\n",
       "  'segregation_duty',\n",
       "  'unbiased',\n",
       "  'safety_soundness',\n",
       "  'organization',\n",
       "  '15d-14_registrant',\n",
       "  'supervisor',\n",
       "  'agent_registrar',\n",
       "  'unfair_deceptive'],\n",
       " 'quality': ['order',\n",
       "  'breadth_depth',\n",
       "  'on-time_delivery',\n",
       "  'relationship',\n",
       "  'quantity',\n",
       "  'steadfast',\n",
       "  'responsiveness',\n",
       "  'client',\n",
       "  'stability',\n",
       "  'exemplary',\n",
       "  'wherewithal',\n",
       "  'installed',\n",
       "  'capable',\n",
       "  'customer-financing',\n",
       "  'reliability',\n",
       "  'monitronics_monitronics',\n",
       "  'recontract',\n",
       "  'excellent',\n",
       "  'degree',\n",
       "  'up-time',\n",
       "  'diversity',\n",
       "  'lead-time',\n",
       "  'intimate_knowledge',\n",
       "  'valuable',\n",
       "  'scalability',\n",
       "  'contracted',\n",
       "  'size',\n",
       "  'typically',\n",
       "  'competitively',\n",
       "  'legally_bind',\n",
       "  'credit-worthy',\n",
       "  'after-sale',\n",
       "  'importance',\n",
       "  'high-value',\n",
       "  'load',\n",
       "  'willingness',\n",
       "  'legally-binding',\n",
       "  'environmental_stewardship',\n",
       "  'service-level',\n",
       "  'exist',\n",
       "  'capability',\n",
       "  'capacity',\n",
       "  'reputation',\n",
       "  'scale',\n",
       "  'breadth',\n",
       "  'demand',\n",
       "  'generally',\n",
       "  'higher-quality',\n",
       "  'level',\n",
       "  'diverse'],\n",
       " 'respect': ['motivation',\n",
       "  'job_seeker',\n",
       "  'unite',\n",
       "  'recruiter',\n",
       "  'teammate',\n",
       "  'passionate',\n",
       "  'career',\n",
       "  'workplace',\n",
       "  'newly-hired',\n",
       "  'experienced_team',\n",
       "  'recruitment',\n",
       "  'incentivize',\n",
       "  'orientation',\n",
       "  'team',\n",
       "  'recruiting',\n",
       "  'recruitment_retention',\n",
       "  'creativity',\n",
       "  'foster_culture',\n",
       "  'leadership',\n",
       "  'recruiting_retention',\n",
       "  'designer_artist',\n",
       "  'volunteerism',\n",
       "  'artistic',\n",
       "  'recruit',\n",
       "  'creative',\n",
       "  'subject-matter_expertise',\n",
       "  'foster',\n",
       "  'teaching',\n",
       "  'everyone',\n",
       "  'entrepreneur',\n",
       "  'customer-facing',\n",
       "  'colleague',\n",
       "  'instructor',\n",
       "  'talented_experienced',\n",
       "  'faculty',\n",
       "  'train',\n",
       "  'teacher',\n",
       "  'motivational',\n",
       "  'competency',\n",
       "  'neos',\n",
       "  'succession_planning',\n",
       "  'motivate',\n",
       "  'strategist',\n",
       "  'talented',\n",
       "  'recruiting_training',\n",
       "  'educate',\n",
       "  'intern',\n",
       "  'veteran',\n",
       "  'animator',\n",
       "  'professionalism'],\n",
       " 'safety': ['workplace',\n",
       "  'everyone',\n",
       "  'comfortable',\n",
       "  'enrich',\n",
       "  'safer',\n",
       "  'awareness',\n",
       "  'importantly',\n",
       "  'vigor',\n",
       "  'help',\n",
       "  'stability',\n",
       "  'workplace_safety',\n",
       "  'health_wellness',\n",
       "  'forefront',\n",
       "  'healthier',\n",
       "  'emergency_preparedness',\n",
       "  'sexual',\n",
       "  'integrity',\n",
       "  'accessibility',\n",
       "  'enhancing',\n",
       "  'aim',\n",
       "  'excellent',\n",
       "  'cleanliness',\n",
       "  'comfort',\n",
       "  \"'re\",\n",
       "  'affordable',\n",
       "  'driving',\n",
       "  'job_seeker',\n",
       "  'wellness',\n",
       "  'environmental_stewardship',\n",
       "  'fight',\n",
       "  'strive',\n",
       "  'safe',\n",
       "  'advocacy',\n",
       "  'safely',\n",
       "  'poise',\n",
       "  'uniformity',\n",
       "  'robust',\n",
       "  'affordability',\n",
       "  'consumer-driven',\n",
       "  'resilience',\n",
       "  'well-being',\n",
       "  'reinforce',\n",
       "  'discipline',\n",
       "  'desire',\n",
       "  'promote',\n",
       "  'pest',\n",
       "  'advocate',\n",
       "  'inpatient_rehabilitative',\n",
       "  'administration_osha',\n",
       "  'female'],\n",
       " 'teamwork': ['strategic_alliance',\n",
       "  'co-marketing',\n",
       "  'alliance',\n",
       "  'teaming',\n",
       "  'partnering',\n",
       "  'collaborate',\n",
       "  'co-development',\n",
       "  'collaborator',\n",
       "  'gates_foundation',\n",
       "  'cleveland_clinic',\n",
       "  'mutually_beneficial',\n",
       "  'co-branding',\n",
       "  'glaxosmithkline_gsk',\n",
       "  'industrialization',\n",
       "  'co-promotional',\n",
       "  'pasteur',\n",
       "  'genentech_wyeth',\n",
       "  'co-development_commercialization',\n",
       "  'intrexon',\n",
       "  'neglected_disease',\n",
       "  'co-development_co-commercialization',\n",
       "  'ono',\n",
       "  'bill_melinda',\n",
       "  'rutgers_university',\n",
       "  'crada',\n",
       "  'mayo_clinic',\n",
       "  'out-licensing',\n",
       "  'collaboration_sanofi',\n",
       "  'collaboration_medimmune',\n",
       "  'pfizer_pfizer',\n",
       "  'adm',\n",
       "  'academic_collaborator',\n",
       "  'co-develop_co-commercialize',\n",
       "  'licensing',\n",
       "  'jdrf',\n",
       "  'spinal_muscular',\n",
       "  'academic_institution',\n",
       "  'collaboration_celgene',\n",
       "  'takeda_takeda',\n",
       "  'medibic',\n",
       "  'yale_university',\n",
       "  'atrophy_foundation',\n",
       "  'pasteur_merieux',\n",
       "  'alticor',\n",
       "  'proactively_communicate',\n",
       "  'co-',\n",
       "  'collaboration_genentech',\n",
       "  'chdi',\n",
       "  'grunenthal',\n",
       "  'daiichi']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_words_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab['coffee_coffee'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35890"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab['coffee_coffee'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "for word in model.vocab:\n",
    "    if model.vocab[word].count in frequency:\n",
    "        frequency[model.vocab[word].count] +=1\n",
    "    else:\n",
    "        frequency[model.vocab[word].count] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209958"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency[1]+frequency[2]+frequency[3]+frequency[4]+frequency[5]+frequency[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'communication': {'archive',\n",
       "  'automation',\n",
       "  'automotive_infotainment',\n",
       "  'backplane_optical',\n",
       "  'carrier-class',\n",
       "  'communications',\n",
       "  'cybersecurity',\n",
       "  'e-mail_instant',\n",
       "  'exterior_module',\n",
       "  'gogo_biz',\n",
       "  'gps_tracking',\n",
       "  'high-speed_broadband',\n",
       "  'internet_connectivity',\n",
       "  'machine-to-machine',\n",
       "  'message',\n",
       "  'messaging',\n",
       "  'notebook_webcam',\n",
       "  'router_avionics',\n",
       "  'satellite-based',\n",
       "  'shenzhen_tianyin',\n",
       "  'switch',\n",
       "  'telecom_datacom',\n",
       "  'telemetry',\n",
       "  'voice_messaging',\n",
       "  'web-enabled_phone',\n",
       "  'wireline_wireless'},\n",
       " 'community': {'addiction_on-line',\n",
       "  'advocacy',\n",
       "  'affordability',\n",
       "  'animal_welfare',\n",
       "  'at-risk_youth',\n",
       "  'attitude_toward',\n",
       "  'backdrop',\n",
       "  'clientele',\n",
       "  'community_low-',\n",
       "  'counseling',\n",
       "  'developmental_disability',\n",
       "  'diagnose_hiv',\n",
       "  'falls_neighboring',\n",
       "  'for-profit',\n",
       "  'foundation_non-profit',\n",
       "  'gaming_sensory',\n",
       "  'gynecologic',\n",
       "  'harassment_discrimination',\n",
       "  'health',\n",
       "  'healthcare-related',\n",
       "  'homeownership',\n",
       "  'housing',\n",
       "  'importantly',\n",
       "  'increasingly_challenging',\n",
       "  'job',\n",
       "  'job_seeker',\n",
       "  'liaison',\n",
       "  'math_science',\n",
       "  'mental_health',\n",
       "  'neighbor',\n",
       "  'non-governmental_organization',\n",
       "  'non-profit_organization',\n",
       "  'nonprofit_organization',\n",
       "  'nurse_practitioner',\n",
       "  'nutrition_capitalizing',\n",
       "  'population',\n",
       "  'psychology',\n",
       "  'rehabilitation_therapist',\n",
       "  'response',\n",
       "  'root_surf',\n",
       "  'safety_everyone',\n",
       "  'specialist_pharmacist',\n",
       "  'unemployment',\n",
       "  'venous_arterial',\n",
       "  'volunteer_life-threatening',\n",
       "  'water_sanitation'},\n",
       " 'hard_work': {'assault_java',\n",
       "  'buzz',\n",
       "  'compelling',\n",
       "  'complimentary_drink',\n",
       "  'dinner',\n",
       "  'easy_convenient',\n",
       "  'eat',\n",
       "  'everywhere',\n",
       "  'fantasy_sport',\n",
       "  'favorite_podcast',\n",
       "  'gift',\n",
       "  'giveaway',\n",
       "  'green',\n",
       "  'instant_booking',\n",
       "  'interactive',\n",
       "  'job_seeker',\n",
       "  'knot',\n",
       "  'listener',\n",
       "  'love',\n",
       "  'motorcycle_bicycle',\n",
       "  'night',\n",
       "  'online_offline',\n",
       "  'passion',\n",
       "  'points',\n",
       "  'primetime_daytime',\n",
       "  'quickly_easily',\n",
       "  'reservations',\n",
       "  'season_pas',\n",
       "  'slot_player',\n",
       "  'stay_comfortable',\n",
       "  'styling',\n",
       "  'ticket',\n",
       "  'tour',\n",
       "  'viggle'},\n",
       " 'innovation': {'adaptability',\n",
       "  'breakthrough',\n",
       "  'focused',\n",
       "  'holistic',\n",
       "  'microbiology',\n",
       "  'organizational_excellence',\n",
       "  'scale',\n",
       "  'simplicity',\n",
       "  'teamwork',\n",
       "  'transform'},\n",
       " 'integrity': {'accountable',\n",
       "  'adherence',\n",
       "  'administers',\n",
       "  'advocate',\n",
       "  'alfred_a.',\n",
       "  'ascs_eyecare',\n",
       "  'best-in-class',\n",
       "  'collaborative_entrepreneurial',\n",
       "  'committee_oversee',\n",
       "  'coordinate',\n",
       "  'council_cross-functional',\n",
       "  'decision_making',\n",
       "  'delegate_day-to-day',\n",
       "  'delegation_authority',\n",
       "  'designate_anti-money',\n",
       "  'dialogue',\n",
       "  'diligent',\n",
       "  'enterprise-wide_appetite',\n",
       "  'erm_framework',\n",
       "  'ermc',\n",
       "  'ermc_recommend',\n",
       "  'ethical_standard',\n",
       "  'fiduciary_responsibility',\n",
       "  'focused_science-based',\n",
       "  'framework',\n",
       "  'honesty_integrity',\n",
       "  'instill',\n",
       "  'integrity_confidentiality',\n",
       "  'intelligent_taking',\n",
       "  'mechanisms_attempt',\n",
       "  'neos',\n",
       "  'nerc_delegate',\n",
       "  'organization',\n",
       "  'oversees_compliance',\n",
       "  'pillar',\n",
       "  'procedure',\n",
       "  'rmr_messrs.',\n",
       "  'roger_smith',\n",
       "  'stakeholder',\n",
       "  'standardization_ermc',\n",
       "  'strict',\n",
       "  'supervise',\n",
       "  'supervised',\n",
       "  'tone_top'},\n",
       " 'quality': {'authenticity',\n",
       "  'best_breed',\n",
       "  'capable',\n",
       "  'capacity',\n",
       "  'carloadings_carload',\n",
       "  'champion_mines',\n",
       "  'coffee_coffee',\n",
       "  'commercialization_picop',\n",
       "  'constructive_workable',\n",
       "  'creditworthiness_case-by-case',\n",
       "  'degree',\n",
       "  'depth',\n",
       "  'developing_ecosystem',\n",
       "  'differentiator_eye',\n",
       "  'distinguishing',\n",
       "  'excessive_burden',\n",
       "  'exchange-traded_standardized',\n",
       "  'exemplary',\n",
       "  'flexibility_responsiveness',\n",
       "  'freshness',\n",
       "  'generally',\n",
       "  'highly_trained',\n",
       "  'intimate_knowledge',\n",
       "  'letters_conditional',\n",
       "  'lmi_ablavar',\n",
       "  'load',\n",
       "  'longer-duration_fixed-rate',\n",
       "  'monitronics_monitronics',\n",
       "  'non-merchandise',\n",
       "  'output',\n",
       "  'reputation_exemplary',\n",
       "  'scalability',\n",
       "  'sheepskin',\n",
       "  'skill',\n",
       "  'sole-source',\n",
       "  'soy_palm',\n",
       "  'specification',\n",
       "  'sustainability_denote',\n",
       "  'talent',\n",
       "  'unfulfilled',\n",
       "  'unreserved_fabric',\n",
       "  'user',\n",
       "  'virco',\n",
       "  'worthy'},\n",
       " 'respect': {'coaching',\n",
       "  'coordinator',\n",
       "  'creativity',\n",
       "  'designer_artist',\n",
       "  'everyone',\n",
       "  'executive',\n",
       "  'faculty',\n",
       "  'faculty_student',\n",
       "  'foster_culture',\n",
       "  'graduate_instructor',\n",
       "  'hire_experienced',\n",
       "  'hiring',\n",
       "  'incentivize',\n",
       "  'intern',\n",
       "  'motivated',\n",
       "  'motivational',\n",
       "  'mouth_guard',\n",
       "  'newly-hired',\n",
       "  'orientation',\n",
       "  'pathologist',\n",
       "  'pdn_network',\n",
       "  'personality',\n",
       "  'pharmacist',\n",
       "  'representatives',\n",
       "  'retain_talented',\n",
       "  'solid_low-fare',\n",
       "  'sport_fan',\n",
       "  'succession_planning',\n",
       "  'talented_experienced',\n",
       "  'technical',\n",
       "  'trainer',\n",
       "  'unite'},\n",
       " 'safety': {'companion_animal',\n",
       "  'everyone',\n",
       "  'healthier',\n",
       "  'nutrition_capitalizing',\n",
       "  'safety_everyone',\n",
       "  'sustainability',\n",
       "  'top_priority',\n",
       "  'woman'},\n",
       " 'teamwork': {'abbvie_glaxosmithkline',\n",
       "  'academic_institution',\n",
       "  'aids_vaccine',\n",
       "  'alticor',\n",
       "  'american_jal',\n",
       "  'atrophy_sma',\n",
       "  'baxter',\n",
       "  'bill_gates',\n",
       "  'biomarker_discovery',\n",
       "  'celgene',\n",
       "  'co-development_commercialization',\n",
       "  'collaboration_allergan',\n",
       "  'collaboration_angiotech',\n",
       "  'collaboration_astellas',\n",
       "  'collaboration_merck',\n",
       "  'collaboration_roche',\n",
       "  'collaborator_licensee',\n",
       "  'dainippon_pharmaceuticals',\n",
       "  'ecc_intrexon',\n",
       "  'forest_laboratories',\n",
       "  'futaba',\n",
       "  'glaxosmithkline_gsk',\n",
       "  'gsk_gsk',\n",
       "  'gsk_lilly',\n",
       "  'industrialization',\n",
       "  'kyowa_hakko',\n",
       "  'licensing',\n",
       "  'muscular_atrophy',\n",
       "  'parkinson',\n",
       "  'scripps',\n",
       "  'sgi_sgi',\n",
       "  'spinal_muscular',\n",
       "  'syngenta',\n",
       "  'wellcome_trust'}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_difference = {}\n",
    "for dimension in seed_words:\n",
    "    res_100 = set(expanded_words_100[dimension])\n",
    "    res_10 = set(expanded_words_10[dimension])\n",
    "    symmetric_difference[dimension] = res_100 ^ res_10\n",
    "#output_dimension_result(symmetric_difference, fname='data/10k_expanded_symmetric_difference.txt', n=50)\n",
    "symmetric_difference"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
